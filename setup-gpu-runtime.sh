#!/bin/bash
#===============================================================================
# K3s GPU ëŸ°íƒ€ì„ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
#
# ì‚¬ìš©ë²•: sudo ./setup-gpu-runtime.sh
#
# ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” K3s containerdë¥¼ NVIDIA ëŸ°íƒ€ì„ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
#===============================================================================

set -e

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }

# Root ê¶Œí•œ í™•ì¸
if [ "$EUID" -ne 0 ]; then
    log_error "ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” root ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤: sudo $0"
    exit 1
fi

log_info "K3s containerd GPU ëŸ°íƒ€ì„ ì„¤ì • ì¤‘..."

# K3s containerd ì„¤ì • ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p /var/lib/rancher/k3s/agent/etc/containerd

# containerd ì„¤ì • í…œí”Œë¦¿ ìƒì„± (runcë„ ìœ ì§€)
cat > /var/lib/rancher/k3s/agent/etc/containerd/config.toml.tmpl << 'EOF'
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
  runtime_type = "io.containerd.runc.v2"

[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
  SystemdCgroup = true

[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia]
  privileged_without_host_devices = false
  runtime_type = "io.containerd.runc.v2"

[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia.options]
  BinaryName = "/usr/bin/nvidia-container-runtime"
  SystemdCgroup = true
EOF

log_success "containerd ì„¤ì • íŒŒì¼ ìƒì„±ë¨"

# K3s ì„œë¹„ìŠ¤ ì¬ì‹œì‘
log_info "K3s ì„œë¹„ìŠ¤ ì¬ì‹œì‘ ì¤‘..."
systemctl restart k3s

# ë…¸ë“œê°€ Ready ìƒíƒœê°€ ë  ë•Œê¹Œì§€ ëŒ€ê¸°
export KUBECONFIG=/etc/rancher/k3s/k3s.yaml
log_info "ë…¸ë“œê°€ Ready ìƒíƒœê°€ ë  ë•Œê¹Œì§€ ëŒ€ê¸° ì¤‘..."

MAX_WAIT=120
WAITED=0
while [ $WAITED -lt $MAX_WAIT ]; do
    STATUS=$(kubectl get nodes -o jsonpath='{.items[0].status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "Unknown")
    if [ "$STATUS" = "True" ]; then
        log_success "ë…¸ë“œê°€ Ready ìƒíƒœì…ë‹ˆë‹¤"
        break
    fi
    echo -n "."
    sleep 5
    WAITED=$((WAITED + 5))
done
echo ""

if [ $WAITED -ge $MAX_WAIT ]; then
    log_warn "ë…¸ë“œê°€ Ready ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤. ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤..."
    kubectl get nodes
fi

# RuntimeClass ìƒì„±
log_info "NVIDIA RuntimeClass ìƒì„± ì¤‘..."
kubectl apply -f - << 'RUNTIMECLASS'
apiVersion: node.k8s.io/v1
kind: RuntimeClass
metadata:
  name: nvidia
handler: nvidia
RUNTIMECLASS

# Device Plugin DaemonSet ì¬ë°°í¬
log_info "NVIDIA Device Plugin ë°°í¬ ì¤‘..."
kubectl delete daemonset -n kube-system nvidia-device-plugin-daemonset --ignore-not-found 2>/dev/null || true
sleep 5

kubectl apply -f - << 'DAEMONSET'
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nvidia-device-plugin-daemonset
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: nvidia-device-plugin-ds
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        name: nvidia-device-plugin-ds
    spec:
      runtimeClassName: nvidia
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      - key: gpu
        operator: Exists
        effect: NoSchedule
      priorityClassName: system-node-critical
      nodeSelector:
        gpu: "true"
      containers:
      - image: nvcr.io/nvidia/k8s-device-plugin:v0.14.3
        name: nvidia-device-plugin-ctr
        env:
        - name: FAIL_ON_INIT_ERROR
          value: "false"
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]
        volumeMounts:
        - name: device-plugin
          mountPath: /var/lib/kubelet/device-plugins
      volumes:
      - name: device-plugin
        hostPath:
          path: /var/lib/kubelet/device-plugins
DAEMONSET

# Device Plugin Podê°€ ìƒì„±ë  ë•Œê¹Œì§€ ëŒ€ê¸°
log_info "Device Plugin Pod ìƒì„± ëŒ€ê¸° ì¤‘..."
sleep 10

MAX_WAIT=90
WAITED=0
while [ $WAITED -lt $MAX_WAIT ]; do
    POD_STATUS=$(kubectl get pods -n kube-system -l name=nvidia-device-plugin-ds -o jsonpath='{.items[0].status.phase}' 2>/dev/null || echo "")
    if [ "$POD_STATUS" = "Running" ]; then
        log_success "Device Plugin Podê°€ Running ìƒíƒœì…ë‹ˆë‹¤"
        break
    fi
    echo -n "."
    sleep 5
    WAITED=$((WAITED + 5))
done
echo ""

# GPU ë¦¬ì†ŒìŠ¤ í™•ì¸ ëŒ€ê¸°
log_info "GPU ë¦¬ì†ŒìŠ¤ ë“±ë¡ ëŒ€ê¸° ì¤‘..."
sleep 20

echo ""
echo "=============================================="
echo "       GPU ì„¤ì • ì™„ë£Œ!"
echo "=============================================="
echo ""

echo "ğŸ“Š ë…¸ë“œ ìƒíƒœ:"
kubectl get nodes
echo ""

echo "ğŸ“¦ NVIDIA Device Plugin ìƒíƒœ:"
kubectl get pods -n kube-system -l name=nvidia-device-plugin-ds
echo ""

# GPU ë¦¬ì†ŒìŠ¤ í™•ì¸
GPU_COUNT=$(kubectl get nodes -o jsonpath='{.items[0].status.allocatable.nvidia\.com/gpu}' 2>/dev/null || echo "")
if [ -n "$GPU_COUNT" ] && [ "$GPU_COUNT" != "0" ]; then
    log_success "GPU ${GPU_COUNT}ê°œê°€ K8sì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤!"
else
    echo ""
    log_warn "GPUê°€ ì•„ì§ í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    log_info "Device Plugin ë¡œê·¸ í™•ì¸:"
    kubectl logs -n kube-system -l name=nvidia-device-plugin-ds --tail=30 2>/dev/null || echo "  ë¡œê·¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
fi
echo ""
